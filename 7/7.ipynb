{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42e78fcb-4c6a-4174-a3f6-7e1d398efc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install nltk -U\n",
    "#!pip install bs4 - U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ca01a42-2c7a-4757-abf1-af925951bffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\pshiv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\pshiv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\pshiv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\pshiv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\pshiv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e406296-f0fb-44e7-bf41-ebb05d2b095a",
   "metadata": {},
   "outputs": [],
   "source": [
    "para='Artificial intelligence is rapidly transforming the world we live in. From self-driving cars to virtual assistants, AI is playing a crucial role in shaping the future. However, with this technological advancement comes the responsibility to ensure ethical and unbiased development. Researchers and developers must work together to create systems that are transparent, accountable, and beneficial for all of humanity'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "808f9e98-2970-4a7d-8e62-fd56fa365502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial intelligence is rapidly transforming the world we live in. From self-driving cars to virtual assistants, AI is playing a crucial role in shaping the future. However, with this technological advancement comes the responsibility to ensure ethical and unbiased development. Researchers and developers must work together to create systems that are transparent, accountable, and beneficial for all of humanity\n"
     ]
    }
   ],
   "source": [
    "print(para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2768c4ec-156a-42e0-83a1-5972f977c2ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Artificial',\n",
       " 'intelligence',\n",
       " 'is',\n",
       " 'rapidly',\n",
       " 'transforming',\n",
       " 'the',\n",
       " 'world',\n",
       " 'we',\n",
       " 'live',\n",
       " 'in.',\n",
       " 'From',\n",
       " 'self-driving',\n",
       " 'cars',\n",
       " 'to',\n",
       " 'virtual',\n",
       " 'assistants,',\n",
       " 'AI',\n",
       " 'is',\n",
       " 'playing',\n",
       " 'a',\n",
       " 'crucial',\n",
       " 'role',\n",
       " 'in',\n",
       " 'shaping',\n",
       " 'the',\n",
       " 'future.',\n",
       " 'However,',\n",
       " 'with',\n",
       " 'this',\n",
       " 'technological',\n",
       " 'advancement',\n",
       " 'comes',\n",
       " 'the',\n",
       " 'responsibility',\n",
       " 'to',\n",
       " 'ensure',\n",
       " 'ethical',\n",
       " 'and',\n",
       " 'unbiased',\n",
       " 'development.',\n",
       " 'Researchers',\n",
       " 'and',\n",
       " 'developers',\n",
       " 'must',\n",
       " 'work',\n",
       " 'together',\n",
       " 'to',\n",
       " 'create',\n",
       " 'systems',\n",
       " 'that',\n",
       " 'are',\n",
       " 'transparent,',\n",
       " 'accountable,',\n",
       " 'and',\n",
       " 'beneficial',\n",
       " 'for',\n",
       " 'all',\n",
       " 'of',\n",
       " 'humanity']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "para.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4503b2bf-3cf4-419e-9e41-97bd6b46cc84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93ea192f-fcb1-4e3d-a639-332a70069870",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = sent_tokenize (para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5a341c5-b637-4379-9607-e5d33c951ff1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'However, with this technological advancement comes the responsibility to ensure ethical and unbiased development.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12d1627b-8290-48cf-b6e8-0cd3b863e612",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = word_tokenize(para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51fb38d4-2b4a-41b0-8b2c-0f4bd0fc5874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Artificial',\n",
       " 'intelligence',\n",
       " 'is',\n",
       " 'rapidly',\n",
       " 'transforming',\n",
       " 'the',\n",
       " 'world',\n",
       " 'we',\n",
       " 'live',\n",
       " 'in',\n",
       " '.',\n",
       " 'From',\n",
       " 'self-driving',\n",
       " 'cars',\n",
       " 'to',\n",
       " 'virtual',\n",
       " 'assistants',\n",
       " ',',\n",
       " 'AI',\n",
       " 'is',\n",
       " 'playing',\n",
       " 'a',\n",
       " 'crucial',\n",
       " 'role',\n",
       " 'in',\n",
       " 'shaping',\n",
       " 'the',\n",
       " 'future',\n",
       " '.',\n",
       " 'However',\n",
       " ',',\n",
       " 'with',\n",
       " 'this',\n",
       " 'technological',\n",
       " 'advancement',\n",
       " 'comes',\n",
       " 'the',\n",
       " 'responsibility',\n",
       " 'to',\n",
       " 'ensure',\n",
       " 'ethical',\n",
       " 'and',\n",
       " 'unbiased',\n",
       " 'development',\n",
       " '.',\n",
       " 'Researchers',\n",
       " 'and',\n",
       " 'developers',\n",
       " 'must',\n",
       " 'work',\n",
       " 'together',\n",
       " 'to',\n",
       " 'create',\n",
       " 'systems',\n",
       " 'that',\n",
       " 'are',\n",
       " 'transparent',\n",
       " ',',\n",
       " 'accountable',\n",
       " ',',\n",
       " 'and',\n",
       " 'beneficial',\n",
       " 'for',\n",
       " 'all',\n",
       " 'of',\n",
       " 'humanity']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4edcf6a-f30e-4f0c-a352-4386165f67d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b10b8814-d324-46ea-bfca-6a15fa91eb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "swords = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "920c845a-f862-430a-ac1e-79e57244ee9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " \"he'd\",\n",
       " \"he'll\",\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " \"he's\",\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " \"i'd\",\n",
       " 'if',\n",
       " \"i'll\",\n",
       " \"i'm\",\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it'd\",\n",
       " \"it'll\",\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " \"i've\",\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she'd\",\n",
       " \"she'll\",\n",
       " \"she's\",\n",
       " 'should',\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " \"should've\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " \"they'd\",\n",
       " \"they'll\",\n",
       " \"they're\",\n",
       " \"they've\",\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " \"we'd\",\n",
       " \"we'll\",\n",
       " \"we're\",\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " \"we've\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " 'your',\n",
       " \"you're\",\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " \"you've\"]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80df7f1b-10ed-4847-966c-1c25a5a768d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [word for word in words if word not in swords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "23c8d031-891f-4d25-99a1-96d33d95622c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Artificial',\n",
       " 'intelligence',\n",
       " 'rapidly',\n",
       " 'transforming',\n",
       " 'world',\n",
       " 'live',\n",
       " '.',\n",
       " 'From',\n",
       " 'self-driving',\n",
       " 'cars',\n",
       " 'virtual',\n",
       " 'assistants',\n",
       " ',',\n",
       " 'AI',\n",
       " 'playing',\n",
       " 'crucial',\n",
       " 'role',\n",
       " 'shaping',\n",
       " 'future',\n",
       " '.',\n",
       " 'However',\n",
       " ',',\n",
       " 'technological',\n",
       " 'advancement',\n",
       " 'comes',\n",
       " 'responsibility',\n",
       " 'ensure',\n",
       " 'ethical',\n",
       " 'unbiased',\n",
       " 'development',\n",
       " '.',\n",
       " 'Researchers',\n",
       " 'developers',\n",
       " 'must',\n",
       " 'work',\n",
       " 'together',\n",
       " 'create',\n",
       " 'systems',\n",
       " 'transparent',\n",
       " ',',\n",
       " 'accountable',\n",
       " ',',\n",
       " 'beneficial',\n",
       " 'humanity']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "88e375ab-f501-4ae5-af46-510c1375126a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [word for word in words if word.lower() not in swords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b39f460e-435e-4323-ad15-3a1d889dad1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Artificial',\n",
       " 'intelligence',\n",
       " 'rapidly',\n",
       " 'transforming',\n",
       " 'world',\n",
       " 'live',\n",
       " '.',\n",
       " 'self-driving',\n",
       " 'cars',\n",
       " 'virtual',\n",
       " 'assistants',\n",
       " ',',\n",
       " 'AI',\n",
       " 'playing',\n",
       " 'crucial',\n",
       " 'role',\n",
       " 'shaping',\n",
       " 'future',\n",
       " '.',\n",
       " 'However',\n",
       " ',',\n",
       " 'technological',\n",
       " 'advancement',\n",
       " 'comes',\n",
       " 'responsibility',\n",
       " 'ensure',\n",
       " 'ethical',\n",
       " 'unbiased',\n",
       " 'development',\n",
       " '.',\n",
       " 'Researchers',\n",
       " 'developers',\n",
       " 'must',\n",
       " 'work',\n",
       " 'together',\n",
       " 'create',\n",
       " 'systems',\n",
       " 'transparent',\n",
       " ',',\n",
       " 'accountable',\n",
       " ',',\n",
       " 'beneficial',\n",
       " 'humanity']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5fbf01c4-b901-4432-a117-315a6eeff953",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1f59fd53-011e-471c-bb97-f7ca359eab13",
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f5458f81-d30b-4f2b-9161-10804c4e9f39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'work'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps.stem('working')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6f95f8e1-3025-4208-90d0-33014ca7a100",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=[ps.stem(word) for word in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d385feba-1855-4764-b405-9aefb48aff5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['artifici',\n",
       " 'intellig',\n",
       " 'rapidli',\n",
       " 'transform',\n",
       " 'world',\n",
       " 'live',\n",
       " '.',\n",
       " 'self-driv',\n",
       " 'car',\n",
       " 'virtual',\n",
       " 'assist',\n",
       " ',',\n",
       " 'ai',\n",
       " 'play',\n",
       " 'crucial',\n",
       " 'role',\n",
       " 'shape',\n",
       " 'futur',\n",
       " '.',\n",
       " 'howev',\n",
       " ',',\n",
       " 'technolog',\n",
       " 'advanc',\n",
       " 'come',\n",
       " 'respons',\n",
       " 'ensur',\n",
       " 'ethic',\n",
       " 'unbias',\n",
       " 'develop',\n",
       " '.',\n",
       " 'research',\n",
       " 'develop',\n",
       " 'must',\n",
       " 'work',\n",
       " 'togeth',\n",
       " 'creat',\n",
       " 'system',\n",
       " 'transpar',\n",
       " ',',\n",
       " 'account',\n",
       " ',',\n",
       " 'benefici',\n",
       " 'human']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fb1a8ec8-075e-4fca-ae16-8affe15576ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f6f78215-6bd0-4ef1-a78e-78cf50de01fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "wnl = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1f1ca23a-a57e-4270-9a17-f18daca18ca1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'work'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wnl.lemmatize('working', pos='v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ef53129e-36bd-4b4f-b8f0-0832cd3cf728",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "went\n",
      "go\n"
     ]
    }
   ],
   "source": [
    "print(ps.stem('went'))\n",
    "print(wnl.lemmatize('went', pos='v'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "561ee29d-721e-4dcc-9cbf-f32a67b529e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "z = [wnl.lemmatize(word,pos='v') for word in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "37d0187b-0f9d-4598-91bb-9c86f8e3e128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Artificial',\n",
       " 'intelligence',\n",
       " 'rapidly',\n",
       " 'transform',\n",
       " 'world',\n",
       " 'live',\n",
       " '.',\n",
       " 'self-driving',\n",
       " 'cars',\n",
       " 'virtual',\n",
       " 'assistants',\n",
       " ',',\n",
       " 'AI',\n",
       " 'play',\n",
       " 'crucial',\n",
       " 'role',\n",
       " 'shape',\n",
       " 'future',\n",
       " '.',\n",
       " 'However',\n",
       " ',',\n",
       " 'technological',\n",
       " 'advancement',\n",
       " 'come',\n",
       " 'responsibility',\n",
       " 'ensure',\n",
       " 'ethical',\n",
       " 'unbiased',\n",
       " 'development',\n",
       " '.',\n",
       " 'Researchers',\n",
       " 'developers',\n",
       " 'must',\n",
       " 'work',\n",
       " 'together',\n",
       " 'create',\n",
       " 'systems',\n",
       " 'transparent',\n",
       " ',',\n",
       " 'accountable',\n",
       " ',',\n",
       " 'beneficial',\n",
       " 'humanity']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "df423670-d34d-492b-a3fb-f226b23c9b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "585f9473-b5c0-4f0e-a219-4ede0b2d7f2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6cd5ee15-11f1-41ac-9edf-8503759a22c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = [word for word in words if word not in string.punctuation]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "64e7af92-b322-4dcd-ab41-99598d2bda0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Artificial',\n",
       " 'intelligence',\n",
       " 'is',\n",
       " 'rapidly',\n",
       " 'transforming',\n",
       " 'the',\n",
       " 'world',\n",
       " 'we',\n",
       " 'live',\n",
       " 'in',\n",
       " 'From',\n",
       " 'self-driving',\n",
       " 'cars',\n",
       " 'to',\n",
       " 'virtual',\n",
       " 'assistants',\n",
       " 'AI',\n",
       " 'is',\n",
       " 'playing',\n",
       " 'a',\n",
       " 'crucial',\n",
       " 'role',\n",
       " 'in',\n",
       " 'shaping',\n",
       " 'the',\n",
       " 'future',\n",
       " 'However',\n",
       " 'with',\n",
       " 'this',\n",
       " 'technological',\n",
       " 'advancement',\n",
       " 'comes',\n",
       " 'the',\n",
       " 'responsibility',\n",
       " 'to',\n",
       " 'ensure',\n",
       " 'ethical',\n",
       " 'and',\n",
       " 'unbiased',\n",
       " 'development',\n",
       " 'Researchers',\n",
       " 'and',\n",
       " 'developers',\n",
       " 'must',\n",
       " 'work',\n",
       " 'together',\n",
       " 'to',\n",
       " 'create',\n",
       " 'systems',\n",
       " 'that',\n",
       " 'are',\n",
       " 'transparent',\n",
       " 'accountable',\n",
       " 'and',\n",
       " 'beneficial',\n",
       " 'for',\n",
       " 'all',\n",
       " 'of',\n",
       " 'humanity']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6db5149a-a0ca-411c-838b-b023e0972ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import pos_tag "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0abba6f4-1a2f-4c7d-9572-78dd1df24c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\pshiv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger_eng')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4ca22bcb-2967-4594-921d-ca6a1e164267",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Artificial', 'JJ'),\n",
       " ('intelligence', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('rapidly', 'RB'),\n",
       " ('transforming', 'VBG'),\n",
       " ('the', 'DT'),\n",
       " ('world', 'NN'),\n",
       " ('we', 'PRP'),\n",
       " ('live', 'VBP'),\n",
       " ('in', 'IN'),\n",
       " ('From', 'NNP'),\n",
       " ('self-driving', 'JJ'),\n",
       " ('cars', 'NNS'),\n",
       " ('to', 'TO'),\n",
       " ('virtual', 'JJ'),\n",
       " ('assistants', 'NNS'),\n",
       " ('AI', 'NNP'),\n",
       " ('is', 'VBZ'),\n",
       " ('playing', 'VBG'),\n",
       " ('a', 'DT'),\n",
       " ('crucial', 'JJ'),\n",
       " ('role', 'NN'),\n",
       " ('in', 'IN'),\n",
       " ('shaping', 'VBG'),\n",
       " ('the', 'DT'),\n",
       " ('future', 'NN'),\n",
       " ('However', 'RB'),\n",
       " ('with', 'IN'),\n",
       " ('this', 'DT'),\n",
       " ('technological', 'JJ'),\n",
       " ('advancement', 'NN'),\n",
       " ('comes', 'VBZ'),\n",
       " ('the', 'DT'),\n",
       " ('responsibility', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('ensure', 'VB'),\n",
       " ('ethical', 'JJ'),\n",
       " ('and', 'CC'),\n",
       " ('unbiased', 'JJ'),\n",
       " ('development', 'NN'),\n",
       " ('Researchers', 'NNP'),\n",
       " ('and', 'CC'),\n",
       " ('developers', 'NNS'),\n",
       " ('must', 'MD'),\n",
       " ('work', 'VB'),\n",
       " ('together', 'RB'),\n",
       " ('to', 'TO'),\n",
       " ('create', 'VB'),\n",
       " ('systems', 'NNS'),\n",
       " ('that', 'WDT'),\n",
       " ('are', 'VBP'),\n",
       " ('transparent', 'JJ'),\n",
       " ('accountable', 'JJ'),\n",
       " ('and', 'CC'),\n",
       " ('beneficial', 'JJ'),\n",
       " ('for', 'IN'),\n",
       " ('all', 'DT'),\n",
       " ('of', 'IN'),\n",
       " ('humanity', 'NN')]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tag(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0011992e-4ddd-4dd2-a552-2de844475a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4e62df04-ad61-4d36-aec1-1530434116ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1f0bab12-73f9-4e64-8c0b-2c601612d51e",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = tfidf.fit_transform(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "878e48bd-7054-4d8b-9a64-9dace40e7140",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59, 51)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ec540299-9a55-461c-a4c5-768db6366d8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;Compressed Sparse Row sparse matrix of dtype ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;Compressed Sparse Row sparse matrix of dtype ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;Compressed Sparse Row sparse matrix of dtype ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;Compressed Sparse Row sparse matrix of dtype ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;Compressed Sparse Row sparse matrix of dtype ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>&lt;Compressed Sparse Row sparse matrix of dtype ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>&lt;Compressed Sparse Row sparse matrix of dtype ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>&lt;Compressed Sparse Row sparse matrix of dtype ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>&lt;Compressed Sparse Row sparse matrix of dtype ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>&lt;Compressed Sparse Row sparse matrix of dtype ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>&lt;Compressed Sparse Row sparse matrix of dtype ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>&lt;Compressed Sparse Row sparse matrix of dtype ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>&lt;Compressed Sparse Row sparse matrix of dtype ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>&lt;Compressed Sparse Row sparse matrix of dtype ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>&lt;Compressed Sparse Row sparse matrix of dtype ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>&lt;Compressed Sparse Row sparse matrix of dtype ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>&lt;Compressed Sparse Row sparse matrix of dtype ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>&lt;Compressed Sparse Row sparse matrix of dtype ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>&lt;Compressed Sparse Row sparse matrix of dtype ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>&lt;Compressed Sparse Row sparse matrix of dtype ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>&lt;Compressed Sparse Row sparse matrix of dtype ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>&lt;Compressed Sparse Row sparse matrix of dtype ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>&lt;Compressed Sparse Row sparse matrix of dtype ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>&lt;Compressed Sparse Row sparse matrix of dtype ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>&lt;Compressed Sparse Row sparse matrix of dtype ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>&lt;Compressed Sparse Row sparse matrix of dtype ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>&lt;Compressed Sparse Row sparse matrix of dtype ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>&lt;Compressed Sparse Row sparse matrix of dtype ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>&lt;Compressed Sparse Row sparse matrix of dtype ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>&lt;Compressed Sparse Row sparse matrix of dtype ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>&lt;Compressed Sparse Row sparse matrix of dtype ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>&lt;Compressed Sparse Row sparse matrix of dtype ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>&lt;Compressed Sparse Row sparse matrix of dtype ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>&lt;Compressed Sparse Row sparse matrix of dtype ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>&lt;Compressed Sparse Row sparse matrix of dtype ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>&lt;Compressed Sparse Row sparse matrix of dtype ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>&lt;Compressed Sparse Row sparse matrix of dtype ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>&lt;Compressed Sparse Row sparse matrix of dtype ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>&lt;Compressed Sparse Row sparse matrix of dtype ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>&lt;Compressed Sparse Row sparse matrix of dtype ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>&lt;Compressed Sparse Row sparse matrix of dtype ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>&lt;Compressed Sparse Row sparse matrix of dtype ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>&lt;Compressed Sparse Row sparse matrix of dtype ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>&lt;Compressed Sparse Row sparse matrix of dtype ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>&lt;Compressed Sparse Row sparse matrix of dtype ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>&lt;Compressed Sparse Row sparse matrix of dtype ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>&lt;Compressed Sparse Row sparse matrix of dtype ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>&lt;Compressed Sparse Row sparse matrix of dtype ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>&lt;Compressed Sparse Row sparse matrix of dtype ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>&lt;Compressed Sparse Row sparse matrix of dtype ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>&lt;Compressed Sparse Row sparse matrix of dtype ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>&lt;Compressed Sparse Row sparse matrix of dtype ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>&lt;Compressed Sparse Row sparse matrix of dtype ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>&lt;Compressed Sparse Row sparse matrix of dtype ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>&lt;Compressed Sparse Row sparse matrix of dtype ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>&lt;Compressed Sparse Row sparse matrix of dtype ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>&lt;Compressed Sparse Row sparse matrix of dtype ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>&lt;Compressed Sparse Row sparse matrix of dtype ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>&lt;Compressed Sparse Row sparse matrix of dtype ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    0\n",
       "0   <Compressed Sparse Row sparse matrix of dtype ...\n",
       "1   <Compressed Sparse Row sparse matrix of dtype ...\n",
       "2   <Compressed Sparse Row sparse matrix of dtype ...\n",
       "3   <Compressed Sparse Row sparse matrix of dtype ...\n",
       "4   <Compressed Sparse Row sparse matrix of dtype ...\n",
       "5   <Compressed Sparse Row sparse matrix of dtype ...\n",
       "6   <Compressed Sparse Row sparse matrix of dtype ...\n",
       "7   <Compressed Sparse Row sparse matrix of dtype ...\n",
       "8   <Compressed Sparse Row sparse matrix of dtype ...\n",
       "9   <Compressed Sparse Row sparse matrix of dtype ...\n",
       "10  <Compressed Sparse Row sparse matrix of dtype ...\n",
       "11  <Compressed Sparse Row sparse matrix of dtype ...\n",
       "12  <Compressed Sparse Row sparse matrix of dtype ...\n",
       "13  <Compressed Sparse Row sparse matrix of dtype ...\n",
       "14  <Compressed Sparse Row sparse matrix of dtype ...\n",
       "15  <Compressed Sparse Row sparse matrix of dtype ...\n",
       "16  <Compressed Sparse Row sparse matrix of dtype ...\n",
       "17  <Compressed Sparse Row sparse matrix of dtype ...\n",
       "18  <Compressed Sparse Row sparse matrix of dtype ...\n",
       "19  <Compressed Sparse Row sparse matrix of dtype ...\n",
       "20  <Compressed Sparse Row sparse matrix of dtype ...\n",
       "21  <Compressed Sparse Row sparse matrix of dtype ...\n",
       "22  <Compressed Sparse Row sparse matrix of dtype ...\n",
       "23  <Compressed Sparse Row sparse matrix of dtype ...\n",
       "24  <Compressed Sparse Row sparse matrix of dtype ...\n",
       "25  <Compressed Sparse Row sparse matrix of dtype ...\n",
       "26  <Compressed Sparse Row sparse matrix of dtype ...\n",
       "27  <Compressed Sparse Row sparse matrix of dtype ...\n",
       "28  <Compressed Sparse Row sparse matrix of dtype ...\n",
       "29  <Compressed Sparse Row sparse matrix of dtype ...\n",
       "30  <Compressed Sparse Row sparse matrix of dtype ...\n",
       "31  <Compressed Sparse Row sparse matrix of dtype ...\n",
       "32  <Compressed Sparse Row sparse matrix of dtype ...\n",
       "33  <Compressed Sparse Row sparse matrix of dtype ...\n",
       "34  <Compressed Sparse Row sparse matrix of dtype ...\n",
       "35  <Compressed Sparse Row sparse matrix of dtype ...\n",
       "36  <Compressed Sparse Row sparse matrix of dtype ...\n",
       "37  <Compressed Sparse Row sparse matrix of dtype ...\n",
       "38  <Compressed Sparse Row sparse matrix of dtype ...\n",
       "39  <Compressed Sparse Row sparse matrix of dtype ...\n",
       "40  <Compressed Sparse Row sparse matrix of dtype ...\n",
       "41  <Compressed Sparse Row sparse matrix of dtype ...\n",
       "42  <Compressed Sparse Row sparse matrix of dtype ...\n",
       "43  <Compressed Sparse Row sparse matrix of dtype ...\n",
       "44  <Compressed Sparse Row sparse matrix of dtype ...\n",
       "45  <Compressed Sparse Row sparse matrix of dtype ...\n",
       "46  <Compressed Sparse Row sparse matrix of dtype ...\n",
       "47  <Compressed Sparse Row sparse matrix of dtype ...\n",
       "48  <Compressed Sparse Row sparse matrix of dtype ...\n",
       "49  <Compressed Sparse Row sparse matrix of dtype ...\n",
       "50  <Compressed Sparse Row sparse matrix of dtype ...\n",
       "51  <Compressed Sparse Row sparse matrix of dtype ...\n",
       "52  <Compressed Sparse Row sparse matrix of dtype ...\n",
       "53  <Compressed Sparse Row sparse matrix of dtype ...\n",
       "54  <Compressed Sparse Row sparse matrix of dtype ...\n",
       "55  <Compressed Sparse Row sparse matrix of dtype ...\n",
       "56  <Compressed Sparse Row sparse matrix of dtype ...\n",
       "57  <Compressed Sparse Row sparse matrix of dtype ...\n",
       "58  <Compressed Sparse Row sparse matrix of dtype ..."
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15e1267-3c80-4531-9a20-29b9220b1e1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3aa1948-c4aa-41c6-8490-5155c90cb152",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccee1e5-66aa-4d1e-a4a1-9c33baba2204",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2bf4ab-bd96-4a05-97dd-0c1fa98e96ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce2bd77-69c8-418c-9e87-2d5331890478",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d9b60f-708c-479b-a123-a324977fcc9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8cf9dd-0e31-4d9f-ad21-2c7db6c3827a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe68d331-6b78-470c-b063-034d627206db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9b6767-b55a-4c01-a3eb-f56d74811024",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83fc5668-a771-4e08-adfd-71a242244f4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6fa5ea-8483-42cc-8576-7c88727ae09d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e37e73-d87c-428c-adf3-ab43e49cddc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b6845c-abfe-4e74-92c5-a95c278e8708",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1317a71a-e6c8-426e-b1e0-ebf0baf71970",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30dde19b-5d1b-4b65-b681-5a88b2b997c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Aim: Extract Sample document and apply following document preprocessing\n",
    " methods: Tokenization, POS Tagging, stop words removal, Stemming and\n",
    " Lemmatization.\n",
    "\n",
    "Theory:\n",
    "Data Preprocessing in Python:\n",
    " Pre-processing refers to the transformations applied to our data before\n",
    " feeding it to the algorithm. Data Preprocessing is a technique that is used to\n",
    " convert the raw data into a clean data set. In other words, whenever the data is\n",
    " gathered from different sources it is collected in raw format which is not feasible\n",
    " for the analysis.\n",
    "\n",
    "Need of Data Preprocessing\n",
    " Data preprocessing improves the accuracy and reliability of machine learning \n",
    " models by removing errors and inconsistencies.\n",
    "\n",
    " It ensures data consistency by eliminating duplicates and standardizing formats\n",
    " for better analysis.\n",
    "\n",
    " Preprocessing enhances algorithm readability by transforming data into a \n",
    " suitable format for machine learning models.\n",
    "\n",
    " It helps prevent overfitting by removing irrelevant or noisy data, improving \n",
    " model generalization to new data.\n",
    "\n",
    "NLP Techniques in data science:\n",
    " 1. Tokenize text using NLTK in python:\n",
    " To run the below python program, (NLTK) natural language toolkit has to be\n",
    " installed in your system.The NLTK module is a massive tool kit, aimed at helping\n",
    " you with the entire Natural Language Processing (NLP) methodology.\n",
    " In order to install NLTK run the following commands in your terminal.\n",
    " • sudo pip install nltk\n",
    " • Then, enter the python shell in your terminal by simply typing python\n",
    " • Type import nltk\n",
    " • nltk.download(‘all’)\n",
    " \n",
    " 2. Removing stop words with NLTK in Python:\n",
    " Data pre-processing prepares information for computers by transforming it into \n",
    " an understandable format. In NLP, a key pre-processing step involves filtering \n",
    " out \"stop words,\" which are considered useless data for analysis. \n",
    "\n",
    " What are Stop Words?\n",
    " Stop words are common words in a language, such as \"a,\" \"the,\" and \"in,\" that \n",
    " carry little meaningful information and are often removed in natural language \n",
    " processing to reduce noise in text data. They help focus analysis on more \n",
    " important words by filtering out these frequently used but insignificant terms.\n",
    "\n",
    " 3.  Lemmatization with NLTK:\n",
    " Lemmatization groups inflected word forms to analyze them as a single base form, \n",
    " considering word context and meaning. Unlike stemming, which simply chops off \n",
    " suffixes, lemmatization performs morphological analysis, making it a preferred \n",
    " text pre-processing technique.\n",
    "\n",
    "  4. Stemming words with NLTK:\n",
    "  Stemming is a process that reduces words to their root or base form by \n",
    "  removing suffixes. For example, \"chocolates,\" \"chocolatey,\" and \"choco\" are \n",
    "  stemmed to \"chocolate,\" and \"retrieval,\" \"retrieved,\" and \"retrieves\" become \n",
    "  \"retrieve.\"\n",
    "   Some more example of stemming for root word \"like\" include:\n",
    "   -> \"likes\"-> \"liked\"-> \"likely\"-> \"liking\n",
    "\n",
    " There are mainly two errors in stemming – Overstemming and Understemming. \n",
    " Overstemming occurs when two words are stemmed to same root that are of \n",
    " different stems. Under-stemming occurs when two words are stemmed to same \n",
    " root that are not of different stems.\n",
    "\n",
    "Libraries Used: \n",
    " 1. NLTK: NLTK is a standard python library that provides a set of diverse \n",
    " algorithms for NLP. It is one of the most used libraries for NLP and \n",
    " Computational Linguistics.\n",
    " \n",
    " 2. Sklearn: It provides a selection of efficient tools for machine learning and \n",
    " statistical modeling including classification, regression, clustering and \n",
    " dimensionality reduction via a consistence interface in Python.\n",
    " \n",
    " 3. Pandas: Pandas is a Python library used for working with data sets. It has \n",
    " functions for analyzing, cleaning, exploring and manipulating data.\n",
    " \n",
    " 4. String: Python String module contains some constants, utility function, and \n",
    " classes for string manipulation\n",
    "\n",
    "Conclusion :\n",
    " In this experiment we have studied about data preprocessingusing natural\n",
    " language processing technique.\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
